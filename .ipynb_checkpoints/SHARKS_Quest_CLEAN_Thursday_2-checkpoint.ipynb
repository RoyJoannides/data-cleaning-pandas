{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11c01d24",
   "metadata": {},
   "source": [
    "# Importing modules, loading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ecdb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01ba96c",
   "metadata": {
    "id": "d01ba96c",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'xlrd'. Install xlrd >= 2.0.1 for xls Excel support Use pip or conda to install xlrd.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py:142\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m     module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xlrd'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.sharkattackfile.net/spreadsheets/GSAF5.xls\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(url)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(io, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, engine\u001b[38;5;241m=\u001b[39mengine)\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1513\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1513\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engines[engine](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_xlrd.py:34\u001b[0m, in \u001b[0;36mXlrdReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03mReader using xlrd engine.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m{storage_options}\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m err_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall xlrd >= 2.0.1 for xls Excel support\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 34\u001b[0m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlrd\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39merr_msg)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py:145\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 145\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'xlrd'. Install xlrd >= 2.0.1 for xls Excel support Use pip or conda to install xlrd."
     ]
    }
   ],
   "source": [
    "url = 'https://www.sharkattackfile.net/spreadsheets/GSAF5.xls'\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed43c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e1dce",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Lose PDF, source, location (and more) columns✅\n",
    "# 2. Handle all the null✅\n",
    "    # Year -> filling missing/value=0 with data from \"Date\" column\n",
    "    # Year -> keeping only data from the last 77 years (75quantile)\n",
    "    # Time and age replace by avg✅\n",
    "# Delete rows with a majority of nulls✅\n",
    "# 4.Check for duplicates✅\n",
    "# 3.Format Data\n",
    "# Creatign new column with \"Month\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Lose PDF, source, location (and more) columns\n",
    "\n",
    "columns_to_drop = ['Location', 'pdf', 'Source','href formula','Unnamed: 11','href', 'Case Number', 'Case Number.1',\n",
    "       'original order', 'Unnamed: 21', 'Unnamed: 22']\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ebba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Year\"\n",
    "# filling missing values (NaN and \"0\") with data from \"Date\"\n",
    "\n",
    "print(f\"Starting this process there were {sum(df['Year'] == 0.0)} values of 'Year' = 0.\\n\"\n",
    "         f\"And 'Year' had {df['Year'].isnull().sum()} NaN values.\")\n",
    "\n",
    "print(df['Year'].describe())\n",
    "\n",
    "#pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# print(df[df[\"Year\"]==0.0][\"Date\"]) # there are entries with year 0, but info at \"Date\"\n",
    "\n",
    "df[\"Date\"] = df[\"Date\"].apply(str) # transforming the \"Date\" to string to be able to manipulate it\n",
    "\n",
    "substring  = [\"BC\", \"B.C.\"] # deleting the rows that are B.C.\n",
    "filter = df[\"Date\"].str.contains('|'.join(substring))\n",
    "df = df[~filter]\n",
    "\n",
    "df = df[~((df[\"Date\"] == \"No date\") & (df[\"Year\"] == 0.0))] # deleting rows that have year=0 and date=no date\n",
    "\n",
    "# adding to year (when year = 0) the 4 consecutive digids from Date\n",
    "df.loc[df['Year'] == 0.0, 'Year'] = df.loc[df['Year'] == 0.0, 'Date'].str.extract(r'(\\d{4})').values\n",
    "\n",
    "# adding to year (when year = NaN) the 4 consecutive digids from Date\n",
    "df.loc[df['Year'].isna(), 'Year'] = df.loc[df['Year'].isna(), 'Date'].str.extract(r'(\\d{4})').values\n",
    "\n",
    "print(f\"Finishing this process there are {sum(df['Year'] == 0.0)} values of 'Year' = 0.\\n\"\n",
    "        f\"And 'Year' has {df['Year'].isnull().sum()} NaN values.\\n\"\n",
    "        \"The missing values were filled in from info from the 'Date' column.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Year\"\n",
    "# keeping only data from the last 77 years (75quantile)\n",
    "\n",
    "print(f\"Starting this process the dataframe has {df.shape[0]} rows.\")\n",
    "\n",
    "df.dropna(subset=\"Year\",inplace=True) # deleting 3 rows with NaN yesr value ->looking at the data they also look to be around the world wars\n",
    "\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "df = df[df['Year'] >= 1947]\n",
    "\n",
    "print(f\"After this process the dataframe has {df.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e867a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Handle all the null\n",
    "df.isnull().sum()\n",
    "df.isnull().any()\n",
    "df.isnull().sum(axis=1)\n",
    "df.dropna(how='all', inplace=True) #drop all rows with all of the 13 values null (-24 rows)\n",
    "\n",
    "# Convert 'Age' column to numeric type to ensure all values are numeric\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "# Replace null values in the 'Age' column with the average age\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "\n",
    "df['Time'] = pd.to_numeric(df['Time'], errors='coerce')\n",
    "df['Time'].fillna(df['Time'].mean(), inplace=True)\n",
    "df.dropna(subset=['Country'], inplace=True) #drop because we have only 50 NaN\n",
    "df.dropna(subset=['Type'], inplace=True) #drop because we have only 16 NaN\n",
    "df.dropna(subset=['Injury'], inplace=True) #drop because we have only 25 NaN\n",
    "#df.dropna(subset=['Year'], inplace=True) #drop because we have only 2 NaN\n",
    "#df.dropna(thresh=10)#with 13 we have 3054 rows, 12 >> 5773, 11 >> 6555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_per_column = {}\n",
    "for col in df.columns:\n",
    "    unique_values_per_column[col] = df[col].unique()\n",
    "    \n",
    "unique_values_per_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c61552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[~df['Sex'].isin(['M', 'F'])].index, inplace=True)\n",
    "#This code filters the DataFrame to retain only rows where the 'Sex' column contains values 'M' or 'F', \n",
    "#effectively removing rows with other values from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['State'].fillna('undefined', inplace=True)\n",
    "#This will replace all non-values in the 'state' column with the word 'undefined'\n",
    "#because we don't need the states for our research and we can still use other values from the same row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69019b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Species '].fillna('unknown', inplace=True)\n",
    "#change all the non values of the species\n",
    "#to 'unknow' because if we dropped them we would lose a significant part of our sample, which could\n",
    "#compromise the credibility of our research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c97bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Activity'].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62137f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN values 'Name'\n",
    "\n",
    "def generate_anonymous_label(counter):\n",
    "    return f'anonymous{counter}'\n",
    "\n",
    "# Initialize a counter\n",
    "counter = 1\n",
    "\n",
    "# Fill missing values in 'name' column with anonymous labels\n",
    "df['Name'].fillna(value=lambda x: generate_anonymous_label(counter), inplace=True)\n",
    "\n",
    "# Increment counter for next iteration\n",
    "counter += 1\n",
    "\n",
    "#Here we replace all the NaN values in the names with Anonimos1, 2, 3 etc. \n",
    "#Because we don't need people's names for our research\n",
    "# And we can still use the information in the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date -> new column Month\n",
    "\n",
    "df['Month'] = df['Date'] # creating a new column for \"Month\"\n",
    "\n",
    "# for date inputs that have seasons, adding the middle month of the season\n",
    "df['Month'] = df['Month'].replace({\"Fall\":\"October\",\"Summer\":\"July\",\"summer\":\"July\",\"Nox\":\"November\",\"Winter\":\"January\",\"2017.06.05\":\"June\",\"2008.01.30\":\"January\",\"02-Ap-2001\":\"April\"},regex=True)\n",
    "\n",
    "\n",
    "# removing words in \"Date\" that don't offer much info, anf will mess up with the r pattern later\n",
    "substring = [\"Early\",\"Reported\",\"Before\",\"Mid\",\"Between\",\"date\",\"and\",\"Late\"]\n",
    "for sub in substring:\n",
    "    df['Month'] = df['Month'].str.replace(sub, '')\n",
    "    \n",
    "df['Month'] = df['Month'].str.extract(r'([A-Za-z]{3})')\n",
    "\n",
    "df['Month'].isna().sum() # these NaN values, are mostly dates that had only year ( df.loc[df['Month'].isna()] )\n",
    "\n",
    "# replacing the values are not months (checked) with NaN values\n",
    "df['Month'] = df['Month'].replace({\"sam\":None,\"Las\":None,\"Cir\":None,\"Pri\":None,\"Aft\":None,\"lat\":None},regex=True)\n",
    "\n",
    "df['Month'].value_counts() # July and August are the most active months\n",
    "\n",
    "df.dropna(subset = \"Month\",inplace=True) # dropping NaN values, around 100+\n",
    "\n",
    "print(f\"There are {df['Month'].isnull().sum()} NaN values in 'Month'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f621db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().sum()) # no duplicated values\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c855d64",
   "metadata": {},
   "source": [
    "# Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c41339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatting Data:\n",
    "\n",
    "#Use round() and format() to format numeric values.\n",
    "#Use f-strings, format() or % to format strings and use string methods like lower(), upper(), title(), strip(), split(), and replace().\n",
    "#Cleaning Column Names:\n",
    "\n",
    "#Use df.columns to access column names.\n",
    "#Modify column names using df.columns or rename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "lowercase_df\n",
    "#not yet applied to df, new variables\n",
    "capitalized_df = df.applymap(lambda x: x.capitalize() if isinstance(x, str) else x)\n",
    "capitalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ea2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3224c871",
    "4da9b3c8",
    "06b7042b",
    "a3c2909d",
    "5a7fd247"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
